{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import scipy.signal as sig\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import mat73\n",
    "import os\n",
    "from masp import shoebox_room_sim as srs\n",
    "from os.path import join as pjoin\n",
    "import copy\n",
    "import spaudiopy as spa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import my modules (helpers.py where I stored all the functions):\n",
    "import helpers as hlp\n",
    "import importlib\n",
    "importlib.reload(hlp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mono2biSH(mono_sig, sh_rir):\n",
    "    # Apply audio to SH IR\n",
    "    # sh_rir: (M, maxSH, 2, 1), which comes from (M, maxSH, nRec, nSrc)\n",
    "    # mono_sig: (1,D)\n",
    "    left = sig.fftconvolve(np.tile(mono_sig[0], (121,1)).T, sh_rir[:,:,0,0], 'full', 0)   \n",
    "    right = sig.fftconvolve(np.tile(mono_sig[0], (121,1)).T, sh_rir[:,:,1,0], 'full', 0)\n",
    "    return np.array([left, right])\n",
    "\n",
    "def mono2sh(mono_sig, sh_rir):\n",
    "    # Apply audio to SH IR\n",
    "    # sh_rir: (M, maxSH, 1, 1), which comes from (M, maxSH, nRec, nSrc)\n",
    "    # mono_sig: (1,D)\n",
    "    head = sig.fftconvolve(np.tile(mono_sig[0], (121,1)).T, sh_rir[:,:,0,0], 'full', 0)   \n",
    "    return head\n",
    "\n",
    "def biSH2bin(sh_sig, decoder):\n",
    "    left = sig.fftconvolve(sh_sig[0], decoder[:,:,0], 'full', 0).sum(1)\n",
    "    right = sig.fftconvolve(sh_sig[1], decoder[:,:,1], 'full', 0).sum(1)\n",
    "    return np.array([left,right])\n",
    "\n",
    "def sh2bin(sh_sig, decoder):\n",
    "    left = sig.fftconvolve(sh_sig, decoder[:,:,0], 'full', 0).sum(1)\n",
    "    right = sig.fftconvolve(sh_sig, decoder[:,:,1], 'full', 0).sum(1)\n",
    "    return np.array([left,right])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_path = 'sounds'\n",
    "maxlim = 2\n",
    "ambi_order = 10\n",
    "fs=48000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- DESIGN SCENE ----------------\n",
    "\n",
    "# --- Room: ---\n",
    "# room dimensions\n",
    "room = np.array([5., 5., 2.5]) \n",
    "rt60 = np.array([.4])\n",
    "# Compute absorption coefficients for desired rt60 and room dimensions\n",
    "abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60)\n",
    "# Small correction for sound absorption coefficients:\n",
    "if sum(rt60_true-rt60>0.05*rt60_true)>0 :\n",
    "    abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60_true + abs(rt60-rt60_true))\n",
    "# Generally, we simulate up to RT60:\n",
    "limits = np.minimum(rt60, maxlim)\n",
    "\n",
    "# --- Receivers: ---\n",
    "# position of the center of the head:\n",
    "head_pos= np.array([room[0]/2, room[1]/2, 1.6]) \n",
    "# head rotation [az, el]\n",
    "head_orient = np.array([0, 0])\n",
    "# position of two receivers on the head (ears):\n",
    "ears_pos=hlp.head_2_ku_ears(head_pos,head_orient)\n",
    "# 3 receivers in total: head center, left ear, right ear\n",
    "mics = np.array([ears_pos[0], ears_pos[1], list(head_pos)]) \n",
    "\n",
    "# --- Source: ---\n",
    "# 1 source position:\n",
    "src_angle=90\n",
    "src_pos= hlp.place_on_circle(head_pos,1,src_angle)\n",
    "src = np.array(src_pos)\n",
    "\n",
    "\n",
    "# --------------- COMPUTE ECHOGRAMS ----------------\n",
    "# Echograms define how many reflections, at what time and from which coordinates:\n",
    "abs_echograms = srs.compute_echograms_sh(room, src, mics, abs_walls, limits, ambi_order)\n",
    "\n",
    "\n",
    "# --------------- RENDER ECHOGRAMS ----------------\n",
    "# based on echograms, RIRs in spherical harmonics are generated for each defined receiver\n",
    "# here there are 3 receivers: head center, left ear, right ear\n",
    "band_centerfreqs=np.array([1000])\n",
    "rirs_sh = srs.render_rirs_sh(abs_echograms, band_centerfreqs, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check array dimensions:\n",
    "print(f\"{room.shape=} -> Room dimensions in cartesian coordinates. Dimension = (3) [x, y, z].\")\n",
    "print(f\"{abs_walls.shape=} -> Wall absorption coefficients per band. Dimension = (nBands, 6).\")\n",
    "print(f\"{limits.shape=} -> Maximum echogram computation time per band.  Dimension = (nBands).\")\n",
    "print(f\"{src.shape=} -> Source position in cartesian coordinates. Dimension = (nSrc, 3) [[x, y, z]].\")\n",
    "print(f\"{mics.shape=} -> Receiver position in cartesian coordinates. Dimension = (nRec, 3) [[x, y, z]].\")\n",
    "print(f\"{abs_echograms.shape=} -> Rendered echograms. Dimension = (nSrc, nRec, nBands)\")\n",
    "print(f\"{rirs_sh.shape=} -> Rendered RIR in SH. Dimension = (M, maxSH, nRec, nSrc)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlp.plot_scene_raw(room,mics,src,perspective=\"xy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- SIGNALS IN SPHERICAL HARMONICS -----------------\n",
    "# Signal in mono is convolved with RIR in SH generated previously \n",
    "\n",
    "# load mono file:\n",
    "src_sig_mono, src_fs = sf.read(pjoin(speech_path, 'pulse_train.wav'))\n",
    "# Resample mono audio:\n",
    "src_sig_mono = sig.resample_poly(src_sig_mono, fs, src_fs)\n",
    "# change shape from (D,) to (1,D):\n",
    "src_sig_mono=np.array(src_sig_mono,ndmin=2)\n",
    "\n",
    "# from mono to spherical harmonics (sh for the head center)\n",
    "src_sig_sh = mono2sh(src_sig_mono, rirs_sh[:,:,2:3,:])\n",
    "# from mono to binaural spherical harmonics (sh for each ear)\n",
    "src_sig_sh_bi = mono2biSH(src_sig_mono, rirs_sh[:,:,0:2,:])\n",
    "\n",
    "\n",
    "# ---> Note! Functions mono2sh and mono2biSH expect a 2-dim array with a signal and a\n",
    "# 4-dim array with RIRs, therefore I use the python slicing - to pick the RIRs for \n",
    "# the third receiver (here corresponding with the center of the head), I use \n",
    "# rirs_sh[:,:,2:3,:] - this picks the correct elements without changing the size of\n",
    "# the array. I also change shape of the signal from (D,) to (1,D). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check array dimensions:\n",
    "print(f\"{src_sig_mono.shape=}\")\n",
    "print(f\"{src_sig_sh.shape=}\")\n",
    "print(f\"{src_sig_sh_bi.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- DECODE FROM SH TO BINAURAL ----------------\n",
    "\n",
    "# load bimagls decoders created in matlab\n",
    "# bimagls takes RIRs in SH of 2 receivers \n",
    "decoder_ku_bimag = mat73.loadmat(pjoin('decoders_ord10', 'Ku100_ALFE_Window_sinEQ_bimag.mat'))['hnm']\n",
    "decoder_ric_bimag = mat73.loadmat(pjoin('decoders_ord10', 'RIC_Front_Omni_ALFE_Window_SinEQ_bimag.mat'))['hnm']\n",
    "\n",
    "# create a magls decoder with spaudiopy using a sofa file\n",
    "# magls takes RIRs in SH of 1 receivers \n",
    "hrirs = spa.io.load_sofa_hrirs('sofas/RIC_Front_Omni_48000Hz.sofa')\n",
    "left, rigth, new_fs = spa.process.resample_hrirs(hrirs.left, hrirs.right, hrirs.fs, fs, 8)\n",
    "hrirs.fs = new_fs\n",
    "hrirs.update_hrirs(left, rigth)\n",
    "decoder_oldb_mag = spa.decoder.magls_bin(hrirs, 10)\n",
    "decoder_oldb_mag=decoder_oldb_mag.T\n",
    "\n",
    "print(f\"{decoder_ku_bimag.shape=}\")\n",
    "print(f\"{decoder_ric_bimag.shape=}\")\n",
    "print(f\"{decoder_oldb_mag.shape=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Source at {src_angle}, BimagLS with RIC data base: \")\n",
    "Audio(biSH2bin(src_sig_sh_bi, decoder_ric_bimag), rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Source at {src_angle}, BimagLS with Ku100 data base: \")\n",
    "Audio(biSH2bin(src_sig_sh_bi, decoder_ku_bimag), rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Source at {src_angle}, magLS with RIC data base: \")\n",
    "Audio(sh2bin(src_sig_sh, decoder_oldb_mag), rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LibriMix3D",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
